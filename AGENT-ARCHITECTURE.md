# Agent Architecture - Ollama Code

## Hierarchie

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   HAUPTAGENT (Festlegbar via -m)   ‚îÇ
‚îÇ   z.B. qwen3-coder:30b oder Claude  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚îÇ delegiert Aufgaben an
               ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚Üì                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Sub-Agent 1‚îÇ    ‚îÇ Sub-Agent 2‚îÇ
‚îÇ granite4   ‚îÇ    ‚îÇ gpt-oss:20b‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Hauptagent festlegen

### Via CLI Parameter

```bash
# Qwen3-Coder als Hauptagent
npm run dev -- chat -m qwen3-coder:30b

# GPT-OSS als Hauptagent
npm run dev -- chat -m gpt-oss:20b

# Granite4 als Hauptagent (schnell!)
npm run dev -- chat -m granite4:micro

# Claude als Hauptagent (wenn verf√ºgbar)
# (erfordert Claude API Key)
npm run dev -- chat -m claude-sonnet-3.5
```

### Via Config File

`~/.ollama-code/config.json`:
```json
{
  "defaultModel": "qwen3-coder:30b",  ‚Üê Hauptagent
  "ollamaUrl": "http://localhost:11434"
}
```

### Via Environment Variable

```bash
export DEFAULT_MODEL=qwen3-coder:30b
npm run dev
```

---

## Wie Sub-Agents gew√§hlt werden

### Automatische Auswahl

Der **Hauptagent** entscheidet, welche Sub-Agents genutzt werden:

```typescript
// Hauptagent bekommt Aufgabe
hauptagent.run("Review code and write tests", {
  model: "qwen3-coder:30b"  // Hauptagent
});

// Hauptagent kann Sub-Agents nutzen:
// - Automatisch basierend auf Task-Type
// - Oder explizit via delegation tool
```

### Sub-Agent-Auswahl-Logik

```typescript
// Im Code
const SubAgentTypes = {
  CodeReviewer: {
    model: 'qwen3-coder:30b',  // Beste Code-Qualit√§t
    systemPrompt: 'Code review specialist'
  },
  FastExecutor: {
    model: 'granite4:micro',   // Schnellste Ausf√ºhrung
    systemPrompt: 'Fast task executor'
  },
  Reasoner: {
    model: 'gpt-oss:20b',      // Bestes Reasoning
    systemPrompt: 'Reasoning specialist'
  }
};
```

---

## Beispiel-Workflows

### Workflow 1: Qwen Haupt + Granite Sub

```bash
$ npm run dev -- chat -m qwen3-coder:30b -v

ollama-code> Analyze this codebase:
  1. Find all TypeScript files (use fast sub-agent)
  2. Review each for bugs (use me, the main agent)
  3. Generate summary (use fast sub-agent)

[Main Agent: qwen3-coder:30b] Analyzing request...
[Sub-Agent: granite4:micro] Finding files...
  ‚úì Found 42 files in 1.2s
[Main Agent: qwen3-coder:30b] Reviewing code...
  ‚úì Found 3 issues in 24s
[Sub-Agent: granite4:micro] Generating summary...
  ‚úì Summary created in 2.1s
```

### Workflow 2: GPT-OSS Haupt + Mixed Subs

```bash
$ npm run dev -- chat -m gpt-oss:20b -v

ollama-code> Complex project: Plan architecture,
  implement core features, write tests

[Main Agent: gpt-oss:20b] Planning...
  ‚úì Architecture planned in 18s

[Sub-Agent: qwen3-coder:30b] Implementing features...
  ‚úì Core implemented in 32s

[Sub-Agent: qwen3-coder:30b] Writing tests...
  ‚úì Tests generated in 28s

[Main Agent: gpt-oss:20b] Final review...
  ‚úì All good!
```

### Workflow 3: Granite Haupt (Speed-Focus)

```bash
$ npm run dev -- chat -m granite4:micro -v

ollama-code> Quick tasks:
  - Create 5 test files
  - Update README
  - Run bash commands

[Main Agent: granite4:micro] Speed mode activated...
  ‚úì All done in 8.2s total!
```

---

## Hauptagent-Eigenschaften

| Hauptagent | Geschwindigkeit | Qualit√§t | Best For |
|------------|----------------|----------|----------|
| **qwen3-coder:30b** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Code-intensive Projects |
| **gpt-oss:20b** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Planning & Reasoning |
| **granite4:micro** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Speed, Simple Tasks |
| **llama3.1:8b** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | General Purpose |

---

## Delegation Control

### Implizite Delegation (Automatisch)

```bash
ollama-code> Help me with these tasks...
# Hauptagent entscheidet automatisch ob/wann delegiert wird
```

### Explizite Delegation

```bash
ollama-code> Delegate these to sub-agents:
  - Task 1: Use granite4:micro
  - Task 2: Use qwen3-coder:30b
  - Task 3: Use gpt-oss:20b
```

### Programmatische Kontrolle

```typescript
import { Agent } from './src/llm/agent.js';
import { SubAgentOrchestrator } from './src/llm/sub-agent.js';

// Hauptagent erstellen
const hauptagent = new Agent(config, toolManager, modelManager);

// Sub-Agent Orchestrator
const orchestrator = new SubAgentOrchestrator(config, toolManager, modelManager);

// Hauptagent nutzt Orchestrator f√ºr Delegation
const response = await hauptagent.run('Complex task', {
  model: 'qwen3-coder:30b'  // Hauptagent festgelegt!
});
```

---

## CLI Flags √úbersicht

```bash
# Hauptagent festlegen
npm run dev -- chat -m qwen3-coder:30b

# Mit Verbose (zeigt Sub-Agent Calls)
npm run dev -- chat -m qwen3-coder:30b -v

# Custom Ollama Server
npm run dev -- chat -m qwen3-coder:30b --url http://remote:11434

# Temperature anpassen
npm run dev -- chat -m gpt-oss:20b -t 0.5

# Alles kombiniert
npm run dev -- chat -m qwen3-coder:30b -v -t 0.7 --url http://localhost:11434
```

---

## Empfohlene Setups

### Setup 1: Balanced (Empfohlen)
```bash
# Hauptagent: Qwen (beste Code-Qualit√§t)
# Sub-Agents: Mix aus Granite (speed) + GPT-OSS (reasoning)
npm run dev -- chat -m qwen3-coder:30b -v
```

### Setup 2: Speed-Focused
```bash
# Hauptagent: Granite (schnellste Antworten)
# Sub-Agents: Auch Granite f√ºr Konsistenz
npm run dev -- chat -m granite4:micro -v
```

### Setup 3: Quality-Focused
```bash
# Hauptagent: Qwen (beste Qualit√§t)
# Sub-Agents: Nur Qwen + GPT-OSS (keine Kompromisse)
npm run dev -- chat -m qwen3-coder:30b -v
```

---

## Wichtige Hinweise

1. **Hauptagent ist der Boss**
   - Entscheidet √ºber Delegation
   - Koordiniert Sub-Agents
   - Fasst Ergebnisse zusammen

2. **Sub-Agents sind Specialists**
   - F√ºhren spezifische Aufgaben aus
   - Berichten an Hauptagent zur√ºck
   - Keine direkte User-Interaktion

3. **Model Loading**
   - Erster Aufruf l√§dt Model (~2-5s)
   - Weitere Aufrufe nutzen Cache (schnell!)
   - Sub-Agents teilen sich Cache

---

## Zusammenfassung

```bash
# DU legst den Hauptagenten fest:
npm run dev -- chat -m <DEIN_MODELL> -v

# Beispiele:
npm run dev -- chat -m qwen3-coder:30b -v   # Code-Profi
npm run dev -- chat -m gpt-oss:20b -v       # Reasoning-Experte
npm run dev -- chat -m granite4:micro -v    # Speed-Demon

# Der Hauptagent nutzt dann automatisch passende Sub-Agents!
```

---

**Fertig zum Loslegen:**
```bash
cd /home/core/dev/bricked-code/ollama-code
npm run dev -- chat -m qwen3-coder:30b -v
```

Dein Hauptagent (qwen3-coder:30b) ist bereit! üöÄ
